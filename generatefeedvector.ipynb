{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns title and dictionary of word counts for an RSS feed\n",
    "def getwordcounts(url):\n",
    "    # Parse the feed\n",
    "    d=feedparser.parse(url)\n",
    "    wc={}\n",
    "    \n",
    "    # Loop over all the entries\n",
    "    for e in d.entries:\n",
    "        if 'summary' in e: summary=e.summary\n",
    "        else: summary=e.description\n",
    "            \n",
    "        # Extract a list of words\n",
    "        words=getwords(e.title+' '+summary)\n",
    "        for word in words:\n",
    "            wc.setdefault(word,0)\n",
    "            wc[word]+=1\n",
    "    return d.feed.title,wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getwords(html):\n",
    "    # Remove all the HTML tags\n",
    "    txt=re.compile(r'<[^>]+>').sub('',html)\n",
    "    \n",
    "    # Split words by all non-alpha characters\n",
    "    words=re.compile(r'[^A-Z^a-z]+').split(txt)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    return [word.lower( ) for word in words if word!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('reddit: the front page of the internet',\n",
       " {'a': 12,\n",
       "  'aawluz': 1,\n",
       "  'about': 1,\n",
       "  'actor': 1,\n",
       "  'after': 1,\n",
       "  'alleges': 1,\n",
       "  'almost': 1,\n",
       "  'am': 1,\n",
       "  'american': 1,\n",
       "  'an': 1,\n",
       "  'antani': 1,\n",
       "  'aonghusmackilkenny': 1,\n",
       "  'are': 1,\n",
       "  'arresting': 1,\n",
       "  'art': 1,\n",
       "  'as': 1,\n",
       "  'aww': 1,\n",
       "  'backstory': 1,\n",
       "  'bale': 1,\n",
       "  'bargain': 1,\n",
       "  'bars': 1,\n",
       "  'bateman': 1,\n",
       "  'beautiful': 1,\n",
       "  'behind': 1,\n",
       "  'belly': 1,\n",
       "  'bigger': 1,\n",
       "  'bikinibottomtwitter': 1,\n",
       "  'blame': 1,\n",
       "  'blocks': 1,\n",
       "  'body': 1,\n",
       "  'borderlands': 1,\n",
       "  'bouncer': 1,\n",
       "  'bouncers': 1,\n",
       "  'boye': 1,\n",
       "  'buddha': 1,\n",
       "  'bus': 1,\n",
       "  'by': 27,\n",
       "  'cake': 1,\n",
       "  'careful': 1,\n",
       "  'cat': 2,\n",
       "  'cfb': 1,\n",
       "  'change': 1,\n",
       "  'christian': 1,\n",
       "  'colorization': 1,\n",
       "  'com': 3,\n",
       "  'comments': 25,\n",
       "  'company': 1,\n",
       "  'cozyplaces': 1,\n",
       "  'cq': 1,\n",
       "  'crappydesign': 1,\n",
       "  'cruise': 2,\n",
       "  'days': 1,\n",
       "  'dbkb': 1,\n",
       "  'detainee': 1,\n",
       "  'dickfromaccounting': 1,\n",
       "  'do': 1,\n",
       "  'does': 1,\n",
       "  'double': 1,\n",
       "  'drive': 1,\n",
       "  'driver': 1,\n",
       "  'drives': 1,\n",
       "  'e': 1,\n",
       "  'easy': 1,\n",
       "  'edit': 2,\n",
       "  'entry': 1,\n",
       "  'enzait': 1,\n",
       "  'episode': 1,\n",
       "  'extensions': 1,\n",
       "  'eyes': 1,\n",
       "  'f': 2,\n",
       "  'fantastic': 1,\n",
       "  'fb': 1,\n",
       "  'feel': 1,\n",
       "  'finally': 1,\n",
       "  'finished': 1,\n",
       "  'firing': 1,\n",
       "  'followed': 1,\n",
       "  'for': 9,\n",
       "  'foreversage': 1,\n",
       "  'format': 1,\n",
       "  'fortnitebr': 1,\n",
       "  'friendliness': 1,\n",
       "  'friends': 1,\n",
       "  'from': 2,\n",
       "  'front': 1,\n",
       "  'funny': 2,\n",
       "  'g': 1,\n",
       "  'gallowboob': 1,\n",
       "  'gaming': 1,\n",
       "  'germantoast': 1,\n",
       "  'get': 1,\n",
       "  'gets': 1,\n",
       "  'giantsmoke': 1,\n",
       "  'gifs': 1,\n",
       "  'girl': 2,\n",
       "  'give': 1,\n",
       "  'goal': 1,\n",
       "  'good': 1,\n",
       "  'grandma': 1,\n",
       "  'groot': 1,\n",
       "  'h': 1,\n",
       "  'had': 1,\n",
       "  'hailed': 1,\n",
       "  'hard': 1,\n",
       "  'he': 2,\n",
       "  'hegdahla': 1,\n",
       "  'hero': 1,\n",
       "  'hidden': 1,\n",
       "  'hill': 1,\n",
       "  'his': 1,\n",
       "  'hmf': 1,\n",
       "  'holdmyfries': 1,\n",
       "  'https': 3,\n",
       "  'human': 1,\n",
       "  'i': 8,\n",
       "  'ice': 1,\n",
       "  'id': 1,\n",
       "  'if': 3,\n",
       "  'im': 1,\n",
       "  'imgur': 1,\n",
       "  'in': 3,\n",
       "  'inspired': 1,\n",
       "  'intense': 1,\n",
       "  'interestingasfuck': 1,\n",
       "  'interview': 1,\n",
       "  'into': 1,\n",
       "  'is': 2,\n",
       "  'it': 4,\n",
       "  'japan': 1,\n",
       "  'jpg': 1,\n",
       "  'just': 1,\n",
       "  'justice': 1,\n",
       "  'justneckbeardthings': 1,\n",
       "  'jwlmkr': 1,\n",
       "  'k': 1,\n",
       "  'kai': 1,\n",
       "  'kept': 1,\n",
       "  'kieran': 1,\n",
       "  'know': 1,\n",
       "  'lavenders': 1,\n",
       "  'lawsuit': 1,\n",
       "  'leg': 1,\n",
       "  'light': 1,\n",
       "  'link': 25,\n",
       "  'london': 1,\n",
       "  'm': 3,\n",
       "  'made': 1,\n",
       "  'mannerisms': 1,\n",
       "  'mascot': 1,\n",
       "  'me': 1,\n",
       "  'media': 1,\n",
       "  'messed': 1,\n",
       "  'messier': 1,\n",
       "  'mida': 1,\n",
       "  'mobile': 1,\n",
       "  'mom': 1,\n",
       "  'mortwellian': 1,\n",
       "  'multi': 1,\n",
       "  'murderedbywords': 1,\n",
       "  'my': 5,\n",
       "  'n': 2,\n",
       "  'news': 1,\n",
       "  'night': 1,\n",
       "  'not': 1,\n",
       "  'nothing': 1,\n",
       "  'o': 2,\n",
       "  'obligatory': 1,\n",
       "  'oddlysatisfying': 1,\n",
       "  'of': 5,\n",
       "  'off': 1,\n",
       "  'officer': 1,\n",
       "  'oldschoolcool': 1,\n",
       "  'omg': 1,\n",
       "  'on': 1,\n",
       "  'one': 1,\n",
       "  'over': 1,\n",
       "  'own': 1,\n",
       "  'page': 1,\n",
       "  'patrese': 1,\n",
       "  'patrick': 1,\n",
       "  'pbs': 1,\n",
       "  'pics': 1,\n",
       "  'picture': 2,\n",
       "  'pierdonia': 1,\n",
       "  'png': 1,\n",
       "  'police': 1,\n",
       "  'post': 1,\n",
       "  'posted': 1,\n",
       "  'posterity': 1,\n",
       "  'prisoner': 1,\n",
       "  'privately': 1,\n",
       "  'psycho': 1,\n",
       "  'pull': 1,\n",
       "  'put': 1,\n",
       "  'question': 1,\n",
       "  'r': 26,\n",
       "  'rarepuppers': 1,\n",
       "  're': 2,\n",
       "  'really': 1,\n",
       "  'replayroyale': 1,\n",
       "  'retweets': 1,\n",
       "  'riccardo': 1,\n",
       "  'ricoslaughtergang': 1,\n",
       "  'run': 1,\n",
       "  's': 5,\n",
       "  'saved': 1,\n",
       "  'says': 1,\n",
       "  'school': 1,\n",
       "  'scuba': 1,\n",
       "  'seeing': 1,\n",
       "  'shackled': 1,\n",
       "  'shakespearesreverse': 1,\n",
       "  'shakyletters': 1,\n",
       "  'share': 1,\n",
       "  'shot': 1,\n",
       "  'shrek': 1,\n",
       "  'sliding': 1,\n",
       "  'slimjones': 1,\n",
       "  'spectacular': 1,\n",
       "  'sports': 1,\n",
       "  'starterpack': 1,\n",
       "  'starterpacks': 1,\n",
       "  'stating': 1,\n",
       "  'status': 1,\n",
       "  'studied': 1,\n",
       "  'submitted': 25,\n",
       "  'sure': 1,\n",
       "  'surrounded': 1,\n",
       "  'suspect': 1,\n",
       "  'sv': 1,\n",
       "  'takes': 1,\n",
       "  'that': 1,\n",
       "  'the': 7,\n",
       "  'thelastairbender': 1,\n",
       "  'theocupier': 1,\n",
       "  'these': 1,\n",
       "  'think': 1,\n",
       "  'thinner': 1,\n",
       "  'this': 8,\n",
       "  'til': 1,\n",
       "  'to': 31,\n",
       "  'todayilearned': 1,\n",
       "  'toledo': 1,\n",
       "  'tom': 1,\n",
       "  'too': 1,\n",
       "  'tool': 1,\n",
       "  'toronto': 1,\n",
       "  'track': 1,\n",
       "  'transport': 1,\n",
       "  'tweet': 1,\n",
       "  'twimg': 1,\n",
       "  'twitter': 1,\n",
       "  'u': 25,\n",
       "  'ulpt': 1,\n",
       "  'uncomfortable': 1,\n",
       "  'under': 1,\n",
       "  'unethicallifeprotips': 1,\n",
       "  'university': 1,\n",
       "  'up': 1,\n",
       "  'use': 1,\n",
       "  'useableimp': 1,\n",
       "  'utoledo': 1,\n",
       "  'very': 2,\n",
       "  'w': 2,\n",
       "  'wait': 1,\n",
       "  'was': 1,\n",
       "  'waste': 1,\n",
       "  'watching': 1,\n",
       "  'what': 2,\n",
       "  'whatcouldgowrong': 1,\n",
       "  'while': 1,\n",
       "  'wife': 1,\n",
       "  'wilde': 1,\n",
       "  'will': 2,\n",
       "  'with': 1,\n",
       "  'without': 1,\n",
       "  'work': 1,\n",
       "  'worldnews': 1,\n",
       "  'wtf': 1,\n",
       "  'y': 1,\n",
       "  'yamamba': 1,\n",
       "  'you': 6,\n",
       "  'z': 1,\n",
       "  'zedzero': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getwordcounts('https://www.reddit.com/.rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "apcount={}\n",
    "wordcounts={}\n",
    "f = open('feedtext.txt','r')\n",
    "while True:\n",
    "    feedurl = f.readline()\n",
    "    if feedurl==\"\": break\n",
    "    title,wc=getwordcounts(feedurl)\n",
    "    wordcounts[title]=wc \n",
    "    for word,count in wc.items( ):\n",
    "        apcount.setdefault(word,0)\n",
    "        if count>1:\n",
    "            apcount[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist=[]\n",
    "for w,bc in apcount.items( ):\n",
    "    wordlist.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=open('blogdata5.txt','w')\n",
    "out.write('Blog')\n",
    "for word in wordlist:\n",
    "    out.write('\\t%s' % word)\n",
    "out.write('\\n')\n",
    "for blog,wc in wordcounts.items( ):\n",
    "    out.write(blog)\n",
    "    for word in wordlist:\n",
    "        if word in wc: out.write('\\t%d' % wc[word])\n",
    "        else: out.write('\\t0')\n",
    "    out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
